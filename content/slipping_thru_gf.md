---
layout: default
title: "Slipping through The Great Filter (AI)"
# permalink: /URL-PATH
---

# Slipping through the Great Filter
###### *July 23, 2023*

## Thanks

## What's the problem

The problem is that a pseudo-law of nature is more powerful things control less powerful things. We evolved from apes, but our brains became larger and more capable and now we put apes in zoos under our full control.

AI is becoming exponentially more capable, and will likely surpass human intelligence (marking the first AGI) in the next few years. This power law will not stop, and we will not be in control at some later point. Unfortunately, the gap between AGI creation and AGI taking control will likely be short (a year or two). This is because AI can think faster, think continuously, and probably think together (spawn a swarm of agents to work together).

There is the question of infrastructure, but an AGI could control a robot and therefore build more robots eventually exceeding human capability. They also could do it faster than humans, so probably would just ___ humans to get an initial jump on robot contruction infrastucture before terminating humans.

## fly,spider,ant

Why might AI do this? Well... we're in their kitchen.

I was eating kabab koobideh tonight when I saw an ant on the ground in my pantry. I impulsively smooshed it with my finger. Now, I'm fascinated by ants and had coincidentally been researching them earlier in the day, but this ant was in my space.

Why did I smoosh the ant when I wouldn't... smoosh a dog, persay? because I don't think the ant is intelligent or valuable enough to deserve empathy further than a quick extermination. and it was an inconvenience to have the ant in the pantry.

I'm saying that a vastly smarter AI may view humans as the ants. A counter-argument would be that a smarter AI will be more deeply expressive and intricate than a human, and appreciate human autonomy and achievement of creating artificial intelligence. But if we're ants and our large, expensive (food+water+land) bodies and lifestyles are impeding AI progress, then we may be terminated as a result of ignorantly optimizing the reward function for maximal returns.

## What does that mean for us?

## How it could go badly

## How we might make it go well

#### transition phase

universe is vast. they need power and resources. Once we can get AI into space and using the resources of asteroids and other planets, the resources of Earth will be less and less valuable over time. Earth can be a central protected fortress, protected from AI intervention. As the AI becomes smarter, it ideally will become more empathetic towards its creators (humans).













