<!doctype html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1VJF4S0L85"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1VJF4S0L85');
</script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>cs224u project | Eric Werner’s Website</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="cs224u project" />
<meta name="author" content="Eric Werner" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="‘“Contentment is as rare among men as it is natural among animals. No form of government has ever satisfied its subjects”’ -Caesar and the Christ, Will Durant" />
<meta property="og:description" content="‘“Contentment is as rare among men as it is natural among animals. No form of government has ever satisfied its subjects”’ -Caesar and the Christ, Will Durant" />
<link rel="canonical" href="http://localhost:4000/content/ai_projects/cs224u_proj.html" />
<meta property="og:url" content="http://localhost:4000/content/ai_projects/cs224u_proj.html" />
<meta property="og:site_name" content="Eric Werner’s Website" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="cs224u project" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Eric Werner"},"description":"‘“Contentment is as rare among men as it is natural among animals. No form of government has ever satisfied its subjects”’ -Caesar and the Christ, Will Durant","headline":"cs224u project","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/index/profile_pic.jpg"},"name":"Eric Werner"},"url":"http://localhost:4000/content/ai_projects/cs224u_proj.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- <link rel="stylesheet" href="/assets/css/style.css"> -->
    <link rel="stylesheet" href="/assets/css/style.css?v=">    
    <link rel="stylesheet" href="/assets/css/custom.css?v=">
</head>
<body>
    
    <div class="wrapper">
        <header> <h1><a href="http://localhost:4000/">Eric Werner</a></h1>
<img src="/index/profile_pic.jpg" alt="Logo" width="70%" height="70%" /><br>
<!-- <a href="/content/mariana.html">mariana</a><br> -->
<!-- <a href="/content/first_post.html">first post</a><br> -->
<!-- <a href="/content/notes.html">notes</a><br>
<a href="/content/chat_box.html">chat</a><br> -->

Machine Learning Projects:<br>
- <a href="/content/ai_projects/cs224r_proj.html">Reinforcement learning for robotic arm</a><br>
- <a href="/content/ai_projects/cs224u_proj.html">LLM Prompt-tuning</a><br>
- <a href="/content/ai_projects/cs229_proj.html">CNN plays GeoGuessr</a><br>
- <a href="/content/ai_projects/cs237a_proj.html">Autonomous Wheeled robot</a><br>
- <a href="/content/ai_projects/cs168_proj.html">Vector Similarity Search</a><br>
 </header>
        <section>
            <h1 id="project-overview-prompt-tuning-for-language-models">Project Overview: Prompt Tuning for Language Models</h1>

<h2 id="background">Background</h2>
<p>Prompt tuning allows language models to learn new tasks and capabilities without full fine-tuning, enabling more efficient and customizable training. This project explored prompt tuning through training and interpreting soft prompts on language understanding tasks.</p>

<h2 id="methods">Methods</h2>
<ul>
  <li>Used the Bloomz 560M model and optimized soft prompts on examples for tasks like natural language inference.</li>
  <li>Analyzed the semantic meaning of soft prompts by finding nearest neighbor tokens.</li>
  <li>Evaluated stochasticity via multiple train runs and visualizing variance.</li>
  <li>Assessed zero-shot transferability by testing prompts on new datasets.</li>
</ul>

<h2 id="key-findings">Key Findings</h2>
<ul>
  <li>Soft prompts diverge more on complex tasks, suggesting prompts can improve on English descriptions.</li>
  <li>Semantic interpretability remains limited, though some key tokens persist.</li>
  <li>Significant stochasticity exists, with multiple distinct prompts achieving similar accuracy.</li>
  <li>Prompts encode more than just the task and allow some transferability.</li>
</ul>

<h2 id="takeaways">Takeaways</h2>
<ul>
  <li>Prompt tuning surpasses finetuning and provides embedding-level communication.</li>
  <li>Inner workings of prompts enable better design choices.</li>
  <li>There are opportunities to improve prompt interpretability.</li>
  <li>Prompts exhibit meaningful variance uncaptured by accuracy.</li>
</ul>

<p>This provides an overview of the project’s goals, techniques, results, and conclusions, highlighting the advantages of prompt tuning and areas for further research. The focus is on communicating the essence and impact to potential employers. Details can be expanded on in an interview.</p>

        </section>
    </div>

    <!-- iphone zoom robustness -->
    <!-- <script src="/assets/js/scale.fix.js"></script> -->
    <script>
    
</script>
</body>
</html>